{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.style.use(\"ggplot\")\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set(font_scale=1.3)\n",
    "from os import path\n",
    "#from PIL import image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, RegexpTokenizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freshness</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>1</td>\n",
       "      <td>Buoyant and lightweight... except for Brando,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176092</th>\n",
       "      <td>0</td>\n",
       "      <td>Years from now, chances are that when people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316086</th>\n",
       "      <td>0</td>\n",
       "      <td>For those of us who want movies to be about s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396557</th>\n",
       "      <td>1</td>\n",
       "      <td>A good-natured, if inconsequential, thrill ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371579</th>\n",
       "      <td>1</td>\n",
       "      <td>Quentin Tarantino's latest film is a deliciou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Freshness                                             Review\n",
       "620             1   Buoyant and lightweight... except for Brando,...\n",
       "176092          0   Years from now, chances are that when people ...\n",
       "316086          0   For those of us who want movies to be about s...\n",
       "396557          1   A good-natured, if inconsequential, thrill ri...\n",
       "371579          1   Quentin Tarantino's latest film is a deliciou..."
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data set as dataframe and use smaller subset\n",
    "#for simple modeling purposes\n",
    "df=pd.read_csv(\"data/rotten_tomatoes_reviews.csv\")\n",
    "df = shuffle(df)\n",
    "df_quick = df[:10000]\n",
    "df_holdout = df[400000:]\n",
    "df_quick.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_dframe(df, col_name = None):\n",
    "    \"\"\"Purpose: Take in a text based Dataframe and return a cleaned text \n",
    "    dataframe by using regex, lowercasing, stripping stop words and lemmatizing\n",
    "    \n",
    "    Input: Dataframe with only text column\n",
    "    Output: Dataframe with only cleaned text column\"\"\"\n",
    "    \n",
    "    #using regexp notation to get rid of numbers in reviews\n",
    "    df[col_name] = df[col_name].str.replace(r'([^a-zA-Z\\s]+?)',\" \")\n",
    "\n",
    "    # 1. Create a set of documents.\n",
    "    df[col_name] = df[col_name].apply(lambda x : x.lower())\n",
    "\n",
    "    # 2. Create a set of tokenized documents.\n",
    "    docs_tokenized = [word_tokenize(content) for content in df[col_name].values]\n",
    "    \n",
    "\n",
    "    # 3. Strip out stop words from each tokenized document.\n",
    "\n",
    "    stop = set(stopwords.words('english'))\n",
    "#    new_stopwords = set([\"film\",\"movie\",\"like\",\"feel\",\"time\",\"little\",\"adject\", \"adds\",\n",
    "#                        \"bestloved\",\"agonizingly\",\"bantamweight\"])\n",
    "#    stop.update(new_stopwords)\n",
    "    docs_stop = [[word for word in words if word not in stop] for words in docs_tokenized]\n",
    "\n",
    "    # Stemming / Lemmatization\n",
    "\n",
    "    # 1. Stem using lemmatizer\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    docs_wordnet = [[wordnet.lemmatize(word) for word in words] for words in docs_stop]\n",
    "\n",
    "    new_element =[]\n",
    "    for element in docs_wordnet:\n",
    "        test = \" \".join(element)\n",
    "        new_element.append(test) \n",
    "    new_series = pd.Series(new_element)\n",
    "    col = \"text\"\n",
    "    cleaned_df = pd.DataFrame(new_series,columns = [col])\n",
    "    return cleaned_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>buoyant lightweight except brando fact rather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year chance people sit around talk enthusiasti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u want movie something empty action minimal sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good natured inconsequential thrill ride shepa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quentin tarantino latest film deliciously ente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>perhaps maclachlan visual vocabulary limited f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>redford honorable job emulating author unsenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>blomkamp far better observer technological beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>akin achieves peaceful balance alongside death...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>light silly instantly forgettable comedy peppe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>returning core basic made original surprise sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bender matter raunchy un pc hangover part ii d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kind rubbish story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>halston tailor made fashionistas fr ric tcheng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>unexpectedly average adventure movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>woman standing man great big corporate beast c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>interpreter smartly mounted thriller seizes mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>suave looking koo offer giggle porn actor rise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>year old novel feminist modern film adaptation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>funny sexy film make feel like floor movie the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>feature subpar visual effect one dimensional c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>reasonably good better robinson biopic could made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>script liu zhenyun becomes ponderous redundant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>clint eastwood make infamous chair speech look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>knowing little case specific found much admire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>watney fear life take backseat stand attitude ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>despite fun scene end movie little believable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>without strong villain charismatic hero clear ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>psych movie us mercifully light touch one keep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>even charismatic dad earpiece calling shot jad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>sharp looking movie blue chip cast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>overstates establishment v youth culture impac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>rest plot time witty time quite reiterative pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>first patient present respectful informative s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>downey funny ever ensures iron man solid insta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>funny spat overextending ch ti concept ad naus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>charlie bartlett ferris bueller drug addled ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>force awakens end feel bittersweet simply badl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>enjoyable fast paced comedy thriller well writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>dennis hopper last movie wasteland cinematic w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>even face face bleak future hottest august ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>offer nothing documentary even long magazine a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>wild satire taught expect iranian cinema mani ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>jordan peele highly entertaining albeit bit mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>filled half baked laugh expect much way christ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>pale colour palette film look like whimsy with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>really strives sneak commentary military indus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>although material lightweight cute amusing film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>hancock still worth seeing glimpse might truly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>story powerful enough give concussion punch fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>director star dynamic made hit first movie tog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>bloated mess make mush king novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>pacing film may brisk action scene energizing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>really mood get ten forced goofiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>luca one subtlety brevity ups wildness outrage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>gervasi steer clear farcical intent surprise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>material probably suited tv miniseries lot gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>ron howard consegue transformar mesmo matem ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>another dumb movie adam sandler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>harry dean stanton talent never forgotten chan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     buoyant lightweight except brando fact rather ...\n",
       "1     year chance people sit around talk enthusiasti...\n",
       "2     u want movie something empty action minimal sh...\n",
       "3     good natured inconsequential thrill ride shepa...\n",
       "4     quentin tarantino latest film deliciously ente...\n",
       "5     perhaps maclachlan visual vocabulary limited f...\n",
       "6     redford honorable job emulating author unsenti...\n",
       "7     blomkamp far better observer technological beh...\n",
       "8     akin achieves peaceful balance alongside death...\n",
       "9     light silly instantly forgettable comedy peppe...\n",
       "10    returning core basic made original surprise sm...\n",
       "11    bender matter raunchy un pc hangover part ii d...\n",
       "12                                   kind rubbish story\n",
       "13    halston tailor made fashionistas fr ric tcheng...\n",
       "14                 unexpectedly average adventure movie\n",
       "15    woman standing man great big corporate beast c...\n",
       "16    interpreter smartly mounted thriller seizes mo...\n",
       "17    suave looking koo offer giggle porn actor rise...\n",
       "18    year old novel feminist modern film adaptation...\n",
       "19    funny sexy film make feel like floor movie the...\n",
       "20    feature subpar visual effect one dimensional c...\n",
       "21    reasonably good better robinson biopic could made\n",
       "22    script liu zhenyun becomes ponderous redundant...\n",
       "23    clint eastwood make infamous chair speech look...\n",
       "24    knowing little case specific found much admire...\n",
       "25    watney fear life take backseat stand attitude ...\n",
       "26    despite fun scene end movie little believable ...\n",
       "27    without strong villain charismatic hero clear ...\n",
       "28    psych movie us mercifully light touch one keep...\n",
       "29    even charismatic dad earpiece calling shot jad...\n",
       "...                                                 ...\n",
       "9970                 sharp looking movie blue chip cast\n",
       "9971  overstates establishment v youth culture impac...\n",
       "9972  rest plot time witty time quite reiterative pi...\n",
       "9973  first patient present respectful informative s...\n",
       "9974  downey funny ever ensures iron man solid insta...\n",
       "9975  funny spat overextending ch ti concept ad naus...\n",
       "9976  charlie bartlett ferris bueller drug addled ag...\n",
       "9977  force awakens end feel bittersweet simply badl...\n",
       "9978  enjoyable fast paced comedy thriller well writ...\n",
       "9979  dennis hopper last movie wasteland cinematic w...\n",
       "9980  even face face bleak future hottest august ste...\n",
       "9981  offer nothing documentary even long magazine a...\n",
       "9982  wild satire taught expect iranian cinema mani ...\n",
       "9983  jordan peele highly entertaining albeit bit mu...\n",
       "9984  filled half baked laugh expect much way christ...\n",
       "9985  pale colour palette film look like whimsy with...\n",
       "9986  really strives sneak commentary military indus...\n",
       "9987    although material lightweight cute amusing film\n",
       "9988  hancock still worth seeing glimpse might truly...\n",
       "9989  story powerful enough give concussion punch fe...\n",
       "9990  director star dynamic made hit first movie tog...\n",
       "9991                  bloated mess make mush king novel\n",
       "9992  pacing film may brisk action scene energizing ...\n",
       "9993               really mood get ten forced goofiness\n",
       "9994  luca one subtlety brevity ups wildness outrage...\n",
       "9995  gervasi steer clear farcical intent surprise i...\n",
       "9996  material probably suited tv miniseries lot gro...\n",
       "9997  ron howard consegue transformar mesmo matem ti...\n",
       "9998                    another dumb movie adam sandler\n",
       "9999  harry dean stanton talent never forgotten chan...\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col= \"Review\"\n",
    "cleaned_df = cleaned_dframe(df_quick.copy(), col)\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2num(cleaned_df, col= None, train=True, cv=None, tfidf=None):\n",
    "    \"\"\"Purpose: receive a df and a column for text and turn text into CountVectorized Data and tfidf\n",
    "    data\n",
    "    \n",
    "    Input: DataFrame with string column to be numerically vectorized\n",
    "    Output: A doc word count matrix and a tfidf matrix as well\"\"\"\n",
    "    \n",
    "    str_data = cleaned_df[col].values\n",
    "    if train == True:\n",
    "        X_counts = cv.fit_transform(str_data)\n",
    "        X_counts_tfidf_arr = tfidf.fit_transform(X_counts).toarray()\n",
    "    else:\n",
    "        X_counts = cv.transform(str_data)\n",
    "        X_counts_tfidf_arr = tfidf.transform(X_counts).toarray()\n",
    "    return X_counts, X_counts_tfidf_arr\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(lowercase=True, tokenizer=None, strip_accents= \"ascii\", stop_words=\"english\",\n",
    "                             analyzer='word', max_df=1.0, min_df=2,ngram_range=(1,1),\n",
    "                             max_features=4500)\n",
    "tfidf = TfidfTransformer(use_idf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<10000x4500 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 87893 stored elements in Compressed Sparse Row format>,\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col2= \"text\"\n",
    "train = True\n",
    "X_counts, X_counts_tfidf_arr = text2num(cleaned_df.copy(), col2, train, cv, tfidf)\n",
    "X_counts, X_counts_tfidf_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:30000]\n",
    "df_test = df[30000:37500]\n",
    "y_train = df_train.Freshness\n",
    "y_test = df_test.Freshness\n",
    "df_train_clean = cleaned_dframe(df_train.copy(),\"Review\")\n",
    "df_test_clean = cleaned_dframe(df_test.copy(),\"Review\")\n",
    "X_counts_train, X_counts_tfidf_arr_train = text2num(df_train_clean.copy(),\"text\",True,cv,tfidf)\n",
    "X_counts_test, X_counts_tfidf_arr_test = text2num(df_test_clean.copy(),\"text\",False,cv,tfidf)\n",
    "X_counts_test,X_counts_tfidf_arr_test\n",
    "df_holdout = df[37500:45000]\n",
    "y_holdout = df_holdout.Freshness\n",
    "df_holdout_clean = cleaned_dframe(df_holdout.copy(),\"Review\")\n",
    "X_counts_holdout, X_counts_tfidf_arr_holdout = text2num(df_holdout_clean.copy(),\"text\",False,cv,tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7926, 0.744, 0.7470666666666667)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.fit(X_counts_tfidf_arr_train, y_train)\n",
    "nb_model.score(X_counts_tfidf_arr_train,y_train), nb_model.score(X_counts_tfidf_arr_test,y_test),nb_model.score(X_counts_tfidf_arr_holdout,y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4988"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem is that i changed the stop words due to misclassifications in my \n",
    "# test set.  This could be data leakage.  Let me check on a holdout set.\n",
    "\n",
    "df_holdout2 = df[30000:35000]\n",
    "y_holdout2 = df_test.Freshness\n",
    "df_holdout_clean2 = cleaned_dframe(df_holdout2.copy(),\"Review\")\n",
    "X_counts_holdout2, X_counts_tfidf_arr_holdout2 = text2num(df_holdout_clean2.copy(),\"text\",False,cv,tfidf)\n",
    "nb_model.score(X_counts_tfidf_arr_holdout2,y_holdout2)\n",
    "\n",
    "#It is unfortunately confirmed.  I do not have enough features or data in my\n",
    "#model to get useful information.  Let's use gridsearch to arrive at a good\n",
    "#small model. Let's start by going back and taking the new stop words out of \n",
    "#stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is really weird.  My test score varies from .72 down to .5 based on\n",
    "# the sample chose.  I suspect that I do not have enough data rows or features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter_candidates = [\n",
    "#   {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "#   {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "# ]\n",
    "parameter_candidates = [{\"max_features\":[5000,10000,20000,100000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data1_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-56a0ebb80395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train the classifier on data1's feature and target data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata1_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data1_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a classifier object with the classifier and parameter candidates\n",
    "clf = GridSearchCV(estimator=nb_model, param_grid=parameter_candidates, cv=5, n_jobs=-1)\n",
    "\n",
    "# Train the classifier on data1's feature and target data\n",
    "clf.fit(data1_features, data1_target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the accuracy score\n",
    "print('Best score for data1:', clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the best parameters for the model found using grid search\n",
    "print('Best C:',clf.best_estimator_.C) \n",
    "print('Best Kernel:',clf.best_estimator_.kernel)\n",
    "print('Best Gamma:',clf.best_estimator_.gamma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
